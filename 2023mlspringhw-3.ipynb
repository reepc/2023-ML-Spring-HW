{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\ntorchvision.__version__\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-04-27T16:35:58.979891Z","iopub.execute_input":"2023-04-27T16:35:58.980898Z","iopub.status.idle":"2023-04-27T16:36:01.696230Z","shell.execute_reply.started":"2023-04-27T16:35:58.980843Z","shell.execute_reply":"2023-04-27T16:36:01.695260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_exp_name=\"sample\"\n\n# Import necessary packages.\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport gc\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n# import torch_xla.distributed.xla_multiprocessing as xmp\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, SubsetRandomSampler, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n#cross validation\nfrom sklearn.model_selection import KFold\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random\n    \n# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\n\n# However, it is also possible to use augmentation in the testing phase.\n# You may use train_tfm to produce a variety of images and then test using ensemble methods\ntrain_tfm = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    transforms.ElasticTransform(),\n    transforms.RandomRotation(degrees=180),\n    transforms.RandomAdjustSharpness(sharpness_factor=2),\n    transforms.RandomAutocontrast(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n])\n\nclass FoodDataset(Dataset):\n\n    def __init__(self,path,tfm=test_tfm,files = None):\n        super(FoodDataset).__init__()\n        self.path = path\n        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files != None:\n            self.files = files\n            \n        self.transform = tfm\n  \n    def __len__(self):\n        return len(self.files)\n  \n    def __getitem__(self,idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        \n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # test has no label\n            \n        return im,label\n\nclass Wide_resnet50_2(nn.Module):\n    def __init__(self) -> None:\n        super(Wide_resnet50_2,self).__init__()\n        self.model=torchvision.models.wide_resnet50_2(weights=None)\n        self.model.conv1=nn.Conv2d(3,64,3,1,1)\n        self.model.fc=nn.Linear(2048,11)\n    \n    def forward(self,x):\n        return self.model(x)\n\n# \"cuda\" only when GPUs are available.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n#TPU\n# device = xm.xla_device()\n\n# The number of batch size.\nbatch_size = 40\n\n# Initialize a model, and put it on the device specified.\nmodel_1 = Wide_resnet50_2()\nmodel_2=torchvision.models.alexnet(weights=None,num_classes=11)\nmodel_3=torchvision.models.vgg16_bn(weights=None,num_classes=11)\n# sample_best='/kaggle/usr/lib/2023mlspringhw_3/sample_best.ckpt'\n# model.load_state_dict(torch.load(sample_best,map_location=device))\nmodel_1.load_state_dict(torch.load('/kaggle/input/ensemble-for-ntu-hw3-cnn/wide_resnet50_2_best.ckpt',map_location=device))\nmodel_2.load_state_dict(torch.load('/kaggle/input/ensemble-for-ntu-hw3-cnn/AlexNet_best.ckpt',map_location=device))\nmodel_3.load_state_dict(torch.load('/kaggle/input/ensemble-for-ntu-hw3-cnn/VGG16_bn_best.ckpt',map_location=device))\n\nclass Ensemble(nn.Module):\n    def __init__(self) -> None:\n        super(Ensemble,self).__init__()\n        self.model1 = model_1\n        self.model2 = model_2\n        self.model3 = model_3\n        \n        # self.model1 = torch.load(\"wide_resnet50_2\")\n        # self.model2 = torch.load(\"AlexNet\")\n        # self.model3 = torch.load(\"VGG16_bn\")\n        path = '/kaggle/input/ensemble-for-ntu-hw3-cnn/'\n        self.model1.load_state_dict(torch.load(f'{path}wide_resnet50_2_best.ckpt', map_location=device))\n        self.model2.load_state_dict(torch.load(f'{path}AlexNet_best.ckpt', map_location=device))\n        self.model3.load_state_dict(torch.load(f'{path}VGG16_bn_best.ckpt', map_location=device))\n\n        self.fc=nn.Linear(11,11)\n        \n    def forward(self,x):\n        out1 = self.model1(x)\n        out2 = self.model2(x)\n        out3 = self.model3(x)\n        return (self.fc(out1+out2+out3))\n        # return (out1+out2+out3)/3\n\n# The number of training epochs.\nn_epochs = 7\n\n# If no improvement in 'patience' epochs, early stop.\npatience = 5\n\n# Construct train and valid datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntrain_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/train\", tfm=train_tfm)\n# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\nvalid_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/valid\", tfm=test_tfm)\n# valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\ndataset = ConcatDataset([train_set, valid_set])\nk = 3\nsplits = KFold(n_splits=k, shuffle=True, random_state=30)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:51:31.827089Z","iopub.execute_input":"2023-05-02T12:51:31.827470Z","iopub.status.idle":"2023-05-02T12:51:52.775290Z","shell.execute_reply.started":"2023-05-02T12:51:31.827436Z","shell.execute_reply":"2023-05-02T12:51:52.774182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_valid(model, model_name, train_loader, valid_loader, epochs = n_epochs):\n    # For the classification task, we use cross-entropy as the measurement of performance.\n    criterion = nn.CrossEntropyLoss()\n\n    # Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-6)\n    \n    # Initialize trackers, these are not parameters and should not be changed\n    stale = 0\n    best_acc = 0\n    for epoch in range(epochs):\n\n        # ---------- Training ----------\n        # Make sure the model is in train mode before training.\n        model.train()\n        # These are used to record information in training.\n        train_loss = []\n        train_accs = []\n\n        for batch in tqdm(train_loader):\n\n            # A batch consists of image data and corresponding labels.\n            imgs, labels = batch\n            #imgs = imgs.half()\n            #print(imgs.shape,labels.shape)\n\n            # Forward the data. (Make sure data and model are on the same device.)\n            logits = model(imgs.to(device))\n\n            # Calculate the cross-entropy loss.\n            # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n            loss = criterion(logits, labels.to(device))\n\n            # Gradients stored in the parameters in the previous step should be cleared out first.\n            optimizer.zero_grad()\n\n            # Compute the gradients for parameters.\n            loss.backward()\n\n            # Clip the gradient norms for stable training.\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n\n            # Update the parameters with computed gradients.\n            optimizer.step()\n            # xm.mark_step()\n\n            # Compute the accuracy for current batch.\n            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n            # Record the loss and accuracy.\n            train_loss.append(loss.item())\n            train_accs.append(acc)\n            \n        train_loss = sum(train_loss) / len(train_loss)\n        train_acc = sum(train_accs) / len(train_accs)\n\n        # Print the information.\n        print(f\"[ Train {model_name} | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n        \n        del train_loss, train_acc\n        \n        # ---------- Validation ----------\n        # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n        model.eval()\n\n        # These are used to record information in validation.\n        valid_loss = []\n        valid_accs = []\n\n        # Iterate the validation set by batches.\n        for batch in tqdm(valid_loader):\n\n            # A batch consists of image data and corresponding labels.\n            imgs, labels = batch\n            #imgs = imgs.half()\n\n            # We don't need gradient in validation.\n            # Using torch.no_grad() accelerates the forward process.\n            with torch.no_grad():\n                logits = model(imgs.to(device))\n\n            # We can still compute the loss (but not the gradient).\n            loss = criterion(logits, labels.to(device))\n\n            # Compute the accuracy for current batch.\n            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n            # Record the loss and accuracy.\n            valid_loss.append(loss.item())\n            valid_accs.append(acc)\n            #break\n\n        # The average loss and accuracy for entire validation set is the average of the recorded values.\n        valid_loss = sum(valid_loss) / len(valid_loss)\n        valid_acc = sum(valid_accs) / len(valid_accs)\n\n        # Print the information.\n        print(f\"[ Valid {model_name} | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n        \n\n        # update logs\n        if valid_acc > best_acc:\n            with open(f\"./{_exp_name}_log.txt\",\"a\"):\n                print(f\"[ Valid {model_name} | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n        else:\n            with open(f\"./{_exp_name}_log.txt\",\"a\"):\n                print(f\"[ Valid {model_name} | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n\n        # save models\n        if valid_acc > best_acc:\n            print(f\"Best model found at epoch {epoch+1}, saving model\")\n            torch.save(model.state_dict(), f\"{model_name}_best.ckpt\") # only save best to prevent output memory exceed error\n            # xm.save(model.state_dict(), f\"{model_name}_best.ckpt\")\n            best_acc = valid_acc\n            stale = 0\n        else:\n            stale += 1\n            if stale > patience:\n                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n                break\n                \n        del valid_loss, valid_acc\n        gc.collect()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-30T20:12:14.197057Z","iopub.execute_input":"2023-04-30T20:12:14.197422Z","iopub.status.idle":"2023-04-30T20:12:14.216899Z","shell.execute_reply.started":"2023-04-30T20:12:14.197387Z","shell.execute_reply":"2023-04-30T20:12:14.214780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train and Cross Validation","metadata":{}},{"cell_type":"code","source":"def train():\n    models = [model_1, model_2, model_3]\n    models_name = ['wide_resnet50_2', 'AlexNet', \"VGG16_bn\", _exp_name]\n    train_epochs = [7, 10, 8, 5]\n    for i in range(len(models)+1):\n        for fold, (train_idx, valid_idx) in enumerate(splits.split(dataset)):\n                # train_and_valid(model=xmp.MpModelWrapper(models[i]).to(device),model_name=models_name[i])\n                print(f\"FOLD:{fold+1}\")\n                \n                train_sampler = SubsetRandomSampler(train_idx)\n                valid_sampler = SubsetRandomSampler(valid_idx)\n                train_loader = DataLoader(dataset, batch_size = batch_size, sampler = train_sampler)\n                valid_loader = DataLoader(dataset, batch_size = batch_size, sampler = valid_sampler)\n                \n                if i==3:\n                    Ensemble().to(device)\n                    Ensemble.load_state_dict(torch.load('/kaggle/input/ensemble-for-ntu-hw3-cnn/sample_best.ckpt'), map_location=device)\n                \n                train_and_valid(model = models[i].to(device),\n                                model_name = models_name[i],\n                                train_loader = train_loader,\n                                valid_loader = valid_loader,\n                                epochs = train_epochs[i])\n            \n# train()","metadata":{"execution":{"iopub.status.busy":"2023-04-30T20:12:14.197057Z","iopub.execute_input":"2023-04-30T20:12:14.197422Z","iopub.status.idle":"2023-04-30T20:12:14.216899Z","shell.execute_reply.started":"2023-04-30T20:12:14.197387Z","shell.execute_reply":"2023-04-30T20:12:14.214780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Ensemble().to(device)\nmodel.load_state_dict(torch.load('/kaggle/usr/lib/2023mlspringhw_3/sample_best.ckpt', map_location = device))\n\nfor fold, (train_idx, valid_idx) in enumerate(splits.split(dataset)):\n    print(f'FOLD {fold+1}')\n    train_sampler = SubsetRandomSampler(train_idx)\n    valid_sampler = SubsetRandomSampler(valid_idx)\n    train_loader = DataLoader(dataset, batch_size = batch_size, sampler = train_sampler)\n    valid_loader = DataLoader(dataset, batch_size = batch_size, sampler = valid_sampler)\n\n    train_and_valid(model = model,\n                    model_name = _exp_name,\n                    train_loader = train_loader,\n                    valid_loader = valid_loader,\n                    epochs = 7\n                   )\n\n# Construct test datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntest_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/test\", tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n\nmodel_best = model.to(device)\n# model_best.load_state_dict(torch.load('/kaggle/input/ensemble-for-ntu-hw3-cnn/sample_best.ckpt'))\nmodel_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\nmodel_best.eval()\nprediction = []\nwith torch.no_grad():\n    for data,_ in tqdm(test_loader):\n        test_pred = model_best(data.to(device))\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n        prediction += test_label.squeeze().tolist()\n\n# create test csv\ndef pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(len(test_set))]\ndf[\"Category\"] = prediction\ndf.to_csv(\"submission.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T12:55:15.289434Z","iopub.execute_input":"2023-05-02T12:55:15.289822Z","iopub.status.idle":"2023-05-02T12:55:57.232660Z","shell.execute_reply.started":"2023-05-02T12:55:15.289783Z","shell.execute_reply":"2023-05-02T12:55:57.231593Z"}},"execution_count":null,"outputs":[]}]}